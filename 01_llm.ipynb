{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>from</th>\n",
       "      <th>body</th>\n",
       "      <th>sent_files</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Check out New Jobs Posted by Top Companies</td>\n",
       "      <td>\"iimjobs.com\" &lt;info@iimjobs.com&gt;</td>\n",
       "      <td>Please Enable Javascript\\n&lt;!DOCTYPE html&gt; &lt;htm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-31 16:34:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lunarflu mentioned you in Hugging Face</td>\n",
       "      <td>Discord &lt;notifications@discord.com&gt;</td>\n",
       "      <td>\\r\\n    &lt;!doctype html&gt;\\r\\n    &lt;html xmlns=\"ht...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-31 15:50:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Comparing with Apple.... too much\"</td>\n",
       "      <td>Reddit &lt;noreply@redditmail.com&gt;</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-31 15:44:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suprriya Kauul ( She / Her / Hers) sent you a ...</td>\n",
       "      <td>LinkedIn &lt;messages-noreply@linkedin.com&gt;</td>\n",
       "      <td>-----------------------------------------\\r\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-31 13:21:48+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rina (Owner)  has a Residential House in Kaikh...</td>\n",
       "      <td>Magicbricks &lt;projectsonmb@magicbricks.com&gt;</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-31 18:47:30+05:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0         Check out New Jobs Posted by Top Companies   \n",
       "1             lunarflu mentioned you in Hugging Face   \n",
       "2                \"Comparing with Apple.... too much\"   \n",
       "3  Suprriya Kauul ( She / Her / Hers) sent you a ...   \n",
       "4  Rina (Owner)  has a Residential House in Kaikh...   \n",
       "\n",
       "                                         from  \\\n",
       "0            \"iimjobs.com\" <info@iimjobs.com>   \n",
       "1         Discord <notifications@discord.com>   \n",
       "2             Reddit <noreply@redditmail.com>   \n",
       "3    LinkedIn <messages-noreply@linkedin.com>   \n",
       "4  Magicbricks <projectsonmb@magicbricks.com>   \n",
       "\n",
       "                                                body sent_files  \\\n",
       "0  Please Enable Javascript\\n<!DOCTYPE html> <htm...        NaN   \n",
       "1  \\r\\n    <!doctype html>\\r\\n    <html xmlns=\"ht...        NaN   \n",
       "2  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 S...        NaN   \n",
       "3  -----------------------------------------\\r\\n\\...        NaN   \n",
       "4  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...        NaN   \n",
       "\n",
       "                        date  \n",
       "0  2024-03-31 16:34:37+00:00  \n",
       "1  2024-03-31 15:50:21+00:00  \n",
       "2  2024-03-31 15:44:47+00:00  \n",
       "3  2024-03-31 13:21:48+00:00  \n",
       "4  2024-03-31 18:47:30+05:30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"./data\")\n",
    "email_df = pd.read_csv(data_dir / \"mail_samples_7th_Apr_24.csv\")\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_types, senders = [], []\n",
    "missed = []\n",
    "for v in email_df[\"from\"].str.strip().values:\n",
    "    buffer = re.findall(r\"\\<(.*)@(.*)\\.com\\>\", v)\n",
    "    if len(buffer):\n",
    "        email_types.append(buffer[0][0])\n",
    "        senders.append(buffer[0][1])\n",
    "    else:\n",
    "        missed.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## email sender and mail type analysis\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "\n",
    "# tmp = defaultdict(lambda: [])\n",
    "# for v1, v2 in zip(email_types, senders):\n",
    "#     tmp[v2].append(v1)\n",
    "# tmp = {k: list(set(tmp[k])) for k in tmp}\n",
    "# with open(\"tmp.json\", \"w\") as file:\n",
    "#     json.dump(tmp, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed = list(set(missed))\n",
    "len(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# model = \"gemma:7b\"\n",
    "model_name = \"openhermes:latest\"\n",
    "model = ChatOllama(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator, Extra\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "class OutEntities(BaseModel):\n",
    "    type: str = Field(description=\"a noun/action-word from the input\")\n",
    "    sender: str = Field(\n",
    "        description=\"a noun word without any '.in'/'ai'/'co.in' etc, which will be stripped\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    # # You can add custom validation logic easily with Pydantic.\n",
    "    # @validator(\"setup\")\n",
    "    # def question_ends_with_question_mark(cls, field):\n",
    "    #     if field[-1] != \"?\":\n",
    "    #         raise ValueError(\"Badly formed question!\")\n",
    "    #     return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keep output verbose, only return the format given.\n",
      "For the case: account-update@amazon.in\n",
      "you extract: {\"type\": \"account-update\", \"sender\": \"amazon\"}\n",
      "\n",
      "In the above case you took the noun/action-item as \"type\"\n",
      "and \"sender\" which is a noun without any \".in\"/\"ai\"/\"co.in\" etc\n",
      "\n",
      "Based on the above case, do the same for the below input\n",
      "\n",
      "# Task\n",
      "You have to extract entities from given \n",
      "\n",
      "- alexey@datatalks.club\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = f\"\"\"\n",
    "# Task\n",
    "You have to extract entities from given \n",
    "\n",
    "- alexey@datatalks.club\n",
    "\"\"\"\n",
    "\n",
    "explanation = \"\"\"\n",
    "Keep output verbose, only return the format given.\n",
    "For the case: account-update@amazon.in\n",
    "you extract: {\"type\": \"account-update\", \"sender\": \"amazon\"}\n",
    "\n",
    "In the above case you took the noun/action-item as \"type\"\n",
    "and \"sender\" which is a noun without any \".in\"/\"ai\"/\"co.in\" etc\n",
    "\n",
    "Based on the above case, do the same for the below input\n",
    "\"\"\"\n",
    "\n",
    "query = f\"{explanation}{task}\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import RetryOutputParser, RegexDictParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=OutEntities)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Answer the user query.\\n{format_instructions}\\n{query}\\n\"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "completion_chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='For the case: alexey@datatalks.club\\nwe extract: {\"type\": \"alexey\", \"sender\": \"datatalks\"}\\n\\nIn this case, we took the noun/action-item as \"type\" and \"sender\" which is a noun without any \".in\"/\"ai\"/\"co.in\" etc.', response_metadata={'model': 'openhermes:latest', 'created_at': '2024-04-07T18:23:42.094867Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'total_duration': 10386806291, 'load_duration': 629871375, 'prompt_eval_count': 381, 'prompt_eval_duration': 3537110000, 'eval_count': 79, 'eval_duration': 6216636000}, id='run-f37f2a31-4c79-4cd0-bfca-da097d32d265-0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = completion_chain.invoke({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'email', 'sender': 'alexey'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "match = re.search(\"\\{.*\\}\", resp.content)\n",
    "if match:\n",
    "    print(json.loads(match.group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(86, 123), match='{\"type\": \"email\", \"sender\": \"alexey\"}'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"tmp.txt\", \"a\") as file:\n",
    "#     for v1, v2 in zip(email_types, senders):\n",
    "#         file.write(f\"{v1} | {v2}\")\n",
    "#         file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Mail sender and action type from sender email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_type, sender = re.findall(\n",
    "    r\"\\<(.*)@(.*)\\.com\\>\", '\"iimjobs.com\" <info@iimjobs.com>'\n",
    ")[0]\n",
    "\n",
    "email_df[\"from\"].apply(lambda x: re.search(r\"\\<(.*)@\\(.*)\\.com>\")).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"\\W\", \"\", email_df[\"subject\"][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm(\n",
    "    f\"\"\"\n",
    "    INPUT:\n",
    "    {email_df[\"subject\"][6]}\n",
    "    \n",
    "    TASK: Extract only the english text from the given sentence, keep output verbose\n",
    "    OUTPUT: Use the output format: \n",
    "\n",
    "    english_text: // place the text here\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class EnglishText(BaseModel):\n",
    "    english_text: str\n",
    "\n",
    "\n",
    "class OutEntities(BaseModel):\n",
    "     = Field(description=\"\")\n",
    "    \n",
    "    \n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=EnglishText)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt_and_model = prompt | llm\n",
    "output = prompt_and_model.invoke(\n",
    "    {\n",
    "        \"query\": f'output the Extracted text, only the english text from the given text: {email_df[\"subject\"][0]}'\n",
    "    }\n",
    ")\n",
    "out = parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using POE wrapper for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from poe_api_wrapper import PoeApi\n",
    "\n",
    "# token = \"FcCAI0DhdVFzH2wL01XC3w==\"\n",
    "# client = PoeApi(token)\n",
    "\n",
    "# bot = \"gpt3_5\"\n",
    "\n",
    "# def ask_poe_gpt(prompt, subject):\n",
    "#     for chunk in client.send_message(bot, prompt.replace(\"{subject}\", subject)):\n",
    "#         pass\n",
    "#     time.sleep(2)\n",
    "#     client.delete_chat(bot, del_all=True)\n",
    "#     return chunk[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ollama use-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "model = \"gemma:7b\"\n",
    "# model = \"phi:latest\"\n",
    "llm = Ollama(\n",
    "    model=model,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "## INPUT MAIL\n",
    "    Subject: {subject}\n",
    "    Email Body: {body}\n",
    "    Email Sender: {sender}\n",
    "\n",
    "## CONTEXT: \n",
    "    You are given an INPUT MAIL that contains the subject and email body and the sender of the email to you.\n",
    "    You are the look at the contents of the mail and its meta data and infer data from the input so that you look for\n",
    "    offers, job requests, bank related mails and Urgency of the email. You also need to look at if there are any trivial info in the mail.\n",
    "    Also pay close attention to the sender email address. Weird looking emails with incorrect spelling and numbers may be spam\n",
    "\n",
    "## TASK: Based on the above CONTEXT, classify the email as \"spam\" or \"not spam\"\n",
    "\n",
    "## OUTPUT FORMAT\n",
    "\n",
    "Only output the following output format and keep output verbose\n",
    "    category: your answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# ## INPUT\n",
    "# Subject: {subject}\n",
    "# Email Body: {body}\n",
    "\n",
    "# ## TASK\n",
    "# Classify the given mail as \"spam\" or \"not_spam\":\n",
    "\n",
    "# Context: the mail is received by the user Sajid Mashroor\n",
    "# Extract relevant keywords from the text your reference but you only finally have to classify the given mail as \"spam\" or \"not_spam\":\n",
    "\n",
    "# ## OUTPUT FORMAT\n",
    "# category: // indicating the classified category i.e., \"spam\" or \"not_spam\"\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = llm(\n",
    "    prompt.replace(\"{subject}\", email_df[\"subject\"][5]).replace(\n",
    "        \"{body}\", email_df[\"body\"][5]\n",
    "    )\n",
    ")\n",
    "# response = llm(\n",
    "#     f'Your task is to classify the given summary as \"spam\" or \"not_spam\" Based on below summary:\\n{summary}'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunked_body(beta, body):\n",
    "#     split_idx = int(beta * len(body))\n",
    "#     return f\"{body[:split_idx]}\\n{body[-split_idx:]}\"\n",
    "\n",
    "# beta = 0.3\n",
    "\n",
    "# print(chunked_body(beta, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(\n",
    "    prompt.replace(\"{subject}\", email_df[\"subject\"][5]).replace(\n",
    "        \"{body}\", email_df[\"body\"][5]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_spam = \"\"\"\n",
    "Given the mail content below; classify the content as spam or important.\n",
    "The user of the mail is Sajid Mashroor. Whether he should delete the mail or keep it, based on the content.\n",
    "\n",
    "Answer in yes or no only. Yes meaning \"Spam\" and No meaning \"Important\"\n",
    "\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmail-automate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
